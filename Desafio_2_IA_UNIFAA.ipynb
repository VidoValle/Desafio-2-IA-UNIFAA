{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Carregar o dataset\n",
        "url = 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/refs/heads/master/wisc_bc_data.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Remover a coluna 'id', que não será utilizada\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Converter a coluna 'diagnosis' em numérica (B = 0, M = 1)\n",
        "df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})\n",
        "\n",
        "# Separar as variáveis preditoras (X) e a variável-alvo (y)\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "# Normalizar as features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dividir o dataset em treino (80%) e teste (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "wWF3-8rFPqfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir o modelo sequencial\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Primeira camada de flattening (não é necessário aqui, mas pode ser usada em outros contextos)\n",
        "    tf.keras.layers.Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "\n",
        "    # Segunda camada oculta com 32 neurônios\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "    # Camada de saída com 1 neurônio (classificação binária) e função de ativação sigmoid\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CieyrfybPttH",
        "outputId": "247f6e4b-13da-4708-88ce-6a631cceb152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.3863 - loss: 0.9779 - val_accuracy: 0.4615 - val_loss: 0.6253\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6276 - loss: 0.5532 - val_accuracy: 0.9560 - val_loss: 0.4235\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.3743 - val_accuracy: 0.9670 - val_loss: 0.3044\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9752 - loss: 0.2550 - val_accuracy: 0.9560 - val_loss: 0.2184\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9650 - loss: 0.1876 - val_accuracy: 0.9451 - val_loss: 0.1660\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9770 - loss: 0.1339 - val_accuracy: 0.9560 - val_loss: 0.1369\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.1171 - val_accuracy: 0.9560 - val_loss: 0.1202\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9758 - loss: 0.0959 - val_accuracy: 0.9670 - val_loss: 0.1104\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.1007 - val_accuracy: 0.9780 - val_loss: 0.1043\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0577 - val_accuracy: 0.9780 - val_loss: 0.0991\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.0643 - val_accuracy: 0.9780 - val_loss: 0.0964\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0588 - val_accuracy: 0.9780 - val_loss: 0.0937\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0582 - val_accuracy: 0.9890 - val_loss: 0.0909\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0590 - val_accuracy: 0.9890 - val_loss: 0.0900\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 0.0470 - val_accuracy: 0.9890 - val_loss: 0.0885\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0471 - val_accuracy: 0.9890 - val_loss: 0.0870\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0484 - val_accuracy: 0.9890 - val_loss: 0.0866\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0415 - val_accuracy: 0.9890 - val_loss: 0.0845\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.0501 - val_accuracy: 0.9780 - val_loss: 0.0838\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0413 - val_accuracy: 0.9780 - val_loss: 0.0856\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0272 - val_accuracy: 0.9780 - val_loss: 0.0843\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0316 - val_accuracy: 0.9670 - val_loss: 0.0857\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0351 - val_accuracy: 0.9670 - val_loss: 0.0845\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9840 - loss: 0.0433 - val_accuracy: 0.9670 - val_loss: 0.0857\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0255 - val_accuracy: 0.9560 - val_loss: 0.0852\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0191 - val_accuracy: 0.9560 - val_loss: 0.0853\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0339 - val_accuracy: 0.9560 - val_loss: 0.0882\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0190 - val_accuracy: 0.9560 - val_loss: 0.0872\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0203 - val_accuracy: 0.9560 - val_loss: 0.0912\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0192 - val_accuracy: 0.9560 - val_loss: 0.0939\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0233 - val_accuracy: 0.9560 - val_loss: 0.0954\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0144 - val_accuracy: 0.9560 - val_loss: 0.0942\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0161 - val_accuracy: 0.9560 - val_loss: 0.0936\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0131 - val_accuracy: 0.9560 - val_loss: 0.0949\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0202 - val_accuracy: 0.9560 - val_loss: 0.0983\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0116 - val_accuracy: 0.9560 - val_loss: 0.0971\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9560 - val_loss: 0.0998\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9560 - val_loss: 0.0996\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9560 - val_loss: 0.1000\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9560 - val_loss: 0.1013\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9560 - val_loss: 0.1026\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.9560 - val_loss: 0.1019\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9560 - val_loss: 0.1028\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9560 - val_loss: 0.1038\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9560 - val_loss: 0.1036\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9560 - val_loss: 0.1045\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.9560 - val_loss: 0.1040\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9560 - val_loss: 0.1089\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9560 - val_loss: 0.1109\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9560 - val_loss: 0.1098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo no conjunto de teste\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Acurácia no conjunto de teste: {accuracy:.2f}')\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Matriz de Confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Matriz de Confusão:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Relatório de Classificação\n",
        "print('Relatório de Classificação:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul99YklgP3J_",
        "outputId": "bae1b483-1065-474f-f717-35541618245a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.1279  \n",
            "Acurácia no conjunto de teste: 0.96\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
            "Matriz de Confusão:\n",
            "[[69  2]\n",
            " [ 2 41]]\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        71\n",
            "           1       0.95      0.95      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    }
  ]
}

# Passo a passo do que foi feito no código:

# 1. Importação das bibliotecas
# pandas é usada para manipulação de dados (carregar e trabalhar com o DataFrame).
# numpy é usada para operações numéricas eficientes.
# tensorflow é a biblioteca principal usada para criar e treinar a rede neural.
# sklearn.model_selection contém train_test_split, que é usado para dividir os dados em conjuntos de treino e teste.
# sklearn.preprocessing fornece StandardScaler, que normaliza os dados.
# sklearn.metrics contém funções para gerar a matriz de confusão e o relatório de classificação, importantes para avaliar o desempenho do modelo.

# 2. Carregar o dataset
# O dataset é carregado diretamente de uma URL usando pandas. Esse dataset contém informações sobre amostras de células de pacientes e é utilizado para prever se o câncer é benigno (B) ou maligno (M).

# 3. Pré-processamento dos dados
# A coluna id foi removida, pois não tem relevância para a classificação.
# A coluna diagnosis é mapeada para valores numéricos: B (benigno) é mapeado para 0 e M (maligno) é mapeado para 1.

# 4. Separação das features e da variável alvo
# X contém todas as variáveis preditoras (as colunas com as características das células).
# y contém a variável alvo (coluna diagnosis), que indica se o câncer é benigno ou maligno.

# 5. Normalização dos dados
# StandardScaler é usado para normalizar os dados.

# 6. Divisão dos dados em treino e teste
# Os dados são divididos em dois conjuntos: treino (80%) e teste (20%).

# 7. Construção do modelo de rede neural
# Um modelo sequencial é criado com 3 camadas.

# 8. Compilação do modelo
# O modelo é compilado usando o otimizador Adam e a função de perda binary_crossentropy.

# 9. Treinamento do modelo
# O modelo é treinado por 50 épocas com um batch_size de 32.

# 10. Avaliação do modelo
# O modelo é avaliado no conjunto de teste, com uma acurácia de 96%.

# 11. Fazer previsões no conjunto de teste
# O modelo faz previsões, convertendo probabilidades em classes.

# 12. Matriz de confusão
# A matriz de confusão mostra como as previsões do modelo se comparam com os valores reais.

# 13. Relatório de classificação
# O relatório de classificação exibe métricas como precision, recall e F1-score.

# Resumo final
# O código treina uma rede neural para classificação binária usando o dataset de câncer de mama de Wisconsin.
# O modelo atinge uma acurácia de 96% no conjunto de teste.
